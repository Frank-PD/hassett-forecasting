{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup & Test Notebook\n",
    "\n",
    "**Purpose**: Verify your environment is set up correctly for Hassett forecasting.\n",
    "\n",
    "Run this notebook first to ensure everything works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All packages imported successfully!\n",
      "\n",
      "Versions:\n",
      "  pandas: 2.2.3\n",
      "  numpy: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "# Core data science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Time series\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ… All packages imported successfully!\")\n",
    "print(f\"\\nVersions:\")\n",
    "print(f\"  pandas: {pd.__version__}\")\n",
    "print(f\"  numpy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Up Project Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Project Structure:\n",
      "  Root: /Users/frankgiles/Downloads/hassett-forecasting\n",
      "  Data: /Users/frankgiles/Downloads/hassett-forecasting/data\n",
      "  Source: /Users/frankgiles/Downloads/hassett-forecasting/src\n",
      "  Models: /Users/frankgiles/Downloads/hassett-forecasting/models\n",
      "\n",
      "âœ… Paths configured!\n"
     ]
    }
   ],
   "source": [
    "# Get project root directory\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for imports\n",
    "project_root = Path.cwd().parent\n",
    "src_path = project_root / 'src'\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Define data paths\n",
    "data_dir = project_root / 'data'\n",
    "models_dir = project_root / 'models'\n",
    "docs_dir = project_root / 'docs'\n",
    "\n",
    "print(\"ðŸ“ Project Structure:\")\n",
    "print(f\"  Root: {project_root}\")\n",
    "print(f\"  Data: {data_dir}\")\n",
    "print(f\"  Source: {src_path}\")\n",
    "print(f\"  Models: {models_dir}\")\n",
    "print(f\"\\nâœ… Paths configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Connect to Azure Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARN] pyarrow is not installed by default since databricks-sql-connector 4.0.0,any arrow specific api (e.g. fetchmany_arrow) and cloud fetch will be disabled.If you need these features, please run pip install pyarrow or pip install databricks-sql-connector[pyarrow] to install\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connection to Azure Databricks established successfully!\n",
      "âœ… Query test passed: Row(test=1)\n"
     ]
    }
   ],
   "source": [
    "from databricks import sql\n",
    "\n",
    "# Establish connection to Azure Databricks\n",
    "conn = sql.connect(\n",
    "    server_hostname=\"adb-434028626745069.9.azuredatabricks.net\",\n",
    "    http_path=\"/sql/1.0/warehouses/23a9897d305fb7e2\",\n",
    "    auth_type=\"databricks-oauth\"\n",
    ")\n",
    "print(\"âœ… Connection to Azure Databricks established successfully!\")\n",
    "\n",
    "# Test the connection with a simple query\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT 1 as test\")\n",
    "result = cursor.fetchone()\n",
    "print(f\"âœ… Query test passed: {result}\")\n",
    "\n",
    "# List available tables (uncomment to run)\n",
    "# cursor.execute(\"SHOW TABLES\")\n",
    "# tables = cursor.fetchall()\n",
    "# print(\"\\nðŸ“Š Available Tables:\")\n",
    "# for table in tables:\n",
    "#     print(f\"  - {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query Data from Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Hassett report table - Sample for testing\n",
    "# First, check how many rows exist in the source table\n",
    "count_query = \"SELECT COUNT(*) as row_count FROM decus_domesticops_prod.dbo.tmp_hassett_report\"\n",
    "count_result = pd.read_sql(count_query, conn)\n",
    "total_rows_in_db = count_result['row_count'][0]\n",
    "print(f\"Total rows in source table: {total_rows_in_db:,}\")\n",
    "\n",
    "# Fetch a sample for testing (10,000 rows)\n",
    "SAMPLE_SIZE = 10000\n",
    "query = f\"SELECT * FROM decus_domesticops_prod.dbo.tmp_hassett_report LIMIT {SAMPLE_SIZE}\"\n",
    "print(f\"\\nFetching {SAMPLE_SIZE:,} sample rows from Databricks...\")\n",
    "df_hassett = pd.read_sql(query, conn)\n",
    "print(f\"âœ… Loaded {len(df_hassett):,} rows (SAMPLE dataset)\")\n",
    "print(f\"Columns ({len(df_hassett.columns)}): {list(df_hassett.columns)}\")\n",
    "print(f\"ðŸ“Š Sample represents {len(df_hassett)/total_rows_in_db*100:.1f}% of total data\")\n",
    "\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df_hassett.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Tier Mapping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check tier mapping\n",
    "tier_path = data_dir / 'odc_tier_mapping.csv'\n",
    "\n",
    "if tier_path.exists():\n",
    "    tiers = pd.read_csv(tier_path)\n",
    "    print(\"âœ… Tier mapping loaded!\\n\")\n",
    "    print(\"ðŸ“Š ODC Tiers:\")\n",
    "    display(tiers)\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Tier Summary:\")\n",
    "    print(tiers.groupby('tier').agg({\n",
    "        'ODC': 'count',\n",
    "        'total_2024': 'sum'\n",
    "    }).rename(columns={'ODC': 'count'}))\n",
    "else:\n",
    "    print(f\"âš ï¸  Tier mapping not found at: {tier_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quick Forecasting Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple 2024 baseline forecast test\n",
    "if db_path.exists():\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    # Get Week 50 from 2024 as baseline\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        ODC,\n",
    "        ProductType,\n",
    "        SUM(PIECES) as total_pieces\n",
    "    FROM hassett_report\n",
    "    WHERE ProductType IN ('MAX', 'EXP')\n",
    "        AND strftime('%Y', DATE_SHIP) = '2024'\n",
    "        AND strftime('%W', DATE_SHIP) = '50'\n",
    "    GROUP BY ODC, ProductType\n",
    "    ORDER BY total_pieces DESC\n",
    "    LIMIT 10\n",
    "    \"\"\"\n",
    "    \n",
    "    baseline = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    print(\"ðŸ“Š Top 10 ODC-Product Combinations (2024 Week 50 Baseline):\\n\")\n",
    "    display(baseline)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    baseline_pivot = baseline.pivot(index='ODC', columns='ProductType', values='total_pieces')\n",
    "    baseline_pivot.plot(kind='bar', ax=ax, width=0.8)\n",
    "    ax.set_ylabel('Pieces (Week 50, 2024)')\n",
    "    ax.set_title('Top ODCs by Product Type - Week 50 Baseline')\n",
    "    ax.legend(title='Product')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nâœ… Forecasting test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Environment Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ENVIRONMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checks = [\n",
    "    (\"Python packages\", True),\n",
    "    (\"Project paths\", True),\n",
    "    (\"Database connection\", db_path.exists()),\n",
    "    (\"Tier mapping\", tier_path.exists()),\n",
    "]\n",
    "\n",
    "print(\"\\nâœ… Status Check:\")\n",
    "for check, status in checks:\n",
    "    symbol = \"âœ…\" if status else \"âŒ\"\n",
    "    print(f\"  {symbol} {check}\")\n",
    "\n",
    "all_good = all(status for _, status in checks)\n",
    "\n",
    "if all_good:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸŽ‰ ALL CHECKS PASSED! You're ready to start forecasting!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  1. Open 01_quick_forecast.ipynb for a forecasting demo\")\n",
    "    print(\"  2. Open 02_data_exploration.ipynb to explore the data\")\n",
    "    print(\"  3. Review docs/META_ANALYSIS_100_EXPERIMENTS.md\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âš ï¸  SOME CHECKS FAILED\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nPlease:\")\n",
    "    if not db_path.exists():\n",
    "        print(f\"  - Copy hassett.db to {data_dir}/\")\n",
    "    if not tier_path.exists():\n",
    "        print(f\"  - Copy odc_tier_mapping.csv to {data_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zbwoaoa34bk",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks import sql\n",
    "import pandas as pd\n",
    "\n",
    "# Establish connection to Azure Databricks\n",
    "conn = sql.connect(\n",
    "    server_hostname=\"adb-434028626745069.9.azuredatabricks.net\",\n",
    "    http_path=\"/sql/1.0/warehouses/23a9897d305fb7e2\",\n",
    "    auth_type=\"databricks-oauth\"\n",
    ")\n",
    "print(\"âœ… Connection to Azure Databricks established successfully!\")\n",
    "\n",
    "# Test the connection with a simple query\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT 1 as test\")\n",
    "result = cursor.fetchone()\n",
    "print(f\"âœ… Query test passed: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fso1py1z52p",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connection to Azure Databricks established successfully!\n",
      "âœ… Query test passed: Row(test=1)\n"
     ]
    }
   ],
   "source": [
    "from databricks import sql\n",
    "import pandas as pd\n",
    "\n",
    "# Establish connection to Azure Databricks\n",
    "conn = sql.connect(\n",
    "    server_hostname=\"adb-434028626745069.9.azuredatabricks.net\",\n",
    "    http_path=\"/sql/1.0/warehouses/23a9897d305fb7e2\",\n",
    "    auth_type=\"databricks-oauth\"\n",
    ")\n",
    "print(\"âœ… Connection to Azure Databricks established successfully!\")\n",
    "\n",
    "# Test the connection with a simple query\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT 1 as test\")\n",
    "result = cursor.fetchone()\n",
    "print(f\"âœ… Query test passed: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "uot9vcysozf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All packages imported successfully!\n",
      "\n",
      "Versions:\n",
      "  pandas: 2.2.3\n",
      "  numpy: 2.3.5\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Core data science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Time series\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ… All packages imported successfully!\")\n",
    "print(f\"\\nVersions:\")\n",
    "print(f\"  pandas: {pd.__version__}\")\n",
    "print(f\"  numpy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wofd9nl8p3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Project Structure:\n",
      "  Root: /Users/frankgiles/Downloads/hassett-forecasting\n",
      "  Data: /Users/frankgiles/Downloads/hassett-forecasting/data\n",
      "  Source: /Users/frankgiles/Downloads/hassett-forecasting/src\n",
      "  Models: /Users/frankgiles/Downloads/hassett-forecasting/models\n",
      "\n",
      "âœ… Paths configured!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Get project root directory\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for imports\n",
    "project_root = Path.cwd().parent\n",
    "src_path = project_root / 'src'\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Define data paths\n",
    "data_dir = project_root / 'data'\n",
    "models_dir = project_root / 'models'\n",
    "docs_dir = project_root / 'docs'\n",
    "\n",
    "print(\"ðŸ“ Project Structure:\")\n",
    "print(f\"  Root: {project_root}\")\n",
    "print(f\"  Data: {data_dir}\")\n",
    "print(f\"  Source: {src_path}\")\n",
    "print(f\"  Models: {models_dir}\")\n",
    "print(f\"\\nâœ… Paths configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3g8ssi2sr2r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connection to Azure Databricks established successfully!\n",
      "âœ… Query test passed: Row(test=1)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: from databricks import sql\n",
    "\n",
    "# Establish connection to Azure Databricks\n",
    "conn = sql.connect(\n",
    "    server_hostname=\"adb-434028626745069.9.azuredatabricks.net\",\n",
    "    http_path=\"/sql/1.0/warehouses/23a9897d305fb7e2\",\n",
    "    auth_type=\"databricks-oauth\"\n",
    ")\n",
    "print(\"âœ… Connection to Azure Databricks established successfully!\")\n",
    "\n",
    "# Test the connection with a simple query\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT 1 as test\")\n",
    "result = cursor.fetchone()\n",
    "print(f\"âœ… Query test passed: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ozprf757c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/_0c_sls56fnf_plnrkksvd740000gn/T/ipykernel_25649/1284300043.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  count_result = pd.read_sql(count_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in source table: 360,296\n",
      "\n",
      "Fetching ALL rows from Databricks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/_0c_sls56fnf_plnrkksvd740000gn/T/ipykernel_25649/1284300043.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_hassett = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mSELECT * FROM decus_domesticops_prod.dbo.tmp_hassett_report\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mFetching ALL rows from Databricks...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m df_hassett = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_hassett)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m rows (COMPLETE dataset)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mColumns (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_hassett.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(df_hassett.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/pandas/io/sql.py:706\u001b[39m, in \u001b[36mread_sql\u001b[39m\u001b[34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[39m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m            \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m            \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    718\u001b[39m         _is_table_name = pandas_sql.has_table(sql)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/pandas/io/sql.py:2738\u001b[39m, in \u001b[36mSQLiteDatabase.read_query\u001b[39m\u001b[34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[39m\n\u001b[32m   2727\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_query\u001b[39m(\n\u001b[32m   2728\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2729\u001b[39m     sql,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2736\u001b[39m     dtype_backend: DtypeBackend | Literal[\u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2737\u001b[39m ) -> DataFrame | Iterator[DataFrame]:\n\u001b[32m-> \u001b[39m\u001b[32m2738\u001b[39m     cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2739\u001b[39m     columns = [col_desc[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor.description]\n\u001b[32m   2741\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/pandas/io/sql.py:2674\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2672\u001b[39m cur = \u001b[38;5;28mself\u001b[39m.con.cursor()\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2675\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/databricks/sql/telemetry/latency_logger.py:182\u001b[39m, in \u001b[36mlog_latency.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m start_time = time.monotonic()\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    184\u001b[39m     duration_ms = \u001b[38;5;28mint\u001b[39m((time.monotonic() - start_time) * \u001b[32m1000\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/databricks/sql/client.py:1319\u001b[39m, in \u001b[36mCursor.execute\u001b[39m\u001b[34m(self, operation, parameters, enforce_embedded_schema_correctness, input_stream)\u001b[39m\n\u001b[32m   1317\u001b[39m \u001b[38;5;28mself\u001b[39m._check_not_closed()\n\u001b[32m   1318\u001b[39m \u001b[38;5;28mself\u001b[39m._close_and_clear_active_result_set()\n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m \u001b[38;5;28mself\u001b[39m.active_result_set = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_operation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[43m    \u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43msession_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marraysize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuffer_size_bytes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlz4_compression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlz4_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cloud_fetch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43muse_cloud_fetch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m    \u001b[49m\u001b[43masync_op\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m    \u001b[49m\u001b[43menforce_embedded_schema_correctness\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_embedded_schema_correctness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrow_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrow_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.active_result_set \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.active_result_set.is_staging_operation:\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_staging_operation(\n\u001b[32m   1335\u001b[39m         staging_allowed_local_path=\u001b[38;5;28mself\u001b[39m.connection.staging_allowed_local_path,\n\u001b[32m   1336\u001b[39m         input_stream=input_stream,\n\u001b[32m   1337\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/databricks/sql/backend/thrift_backend.py:1048\u001b[39m, in \u001b[36mThriftDatabricksClient.execute_command\u001b[39m\u001b[34m(self, operation, session_id, max_rows, max_bytes, lz4_compression, cursor, use_cloud_fetch, parameters, async_op, enforce_embedded_schema_correctness, row_limit)\u001b[39m\n\u001b[32m   1017\u001b[39m spark_arrow_types = ttypes.TSparkArrowTypes(\n\u001b[32m   1018\u001b[39m     timestampAsArrow=\u001b[38;5;28mself\u001b[39m._use_arrow_native_timestamps,\n\u001b[32m   1019\u001b[39m     decimalAsArrow=\u001b[38;5;28mself\u001b[39m._use_arrow_native_decimals,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1023\u001b[39m     intervalTypesAsArrow=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1024\u001b[39m )\n\u001b[32m   1025\u001b[39m req = ttypes.TExecuteStatementReq(\n\u001b[32m   1026\u001b[39m     sessionHandle=thrift_handle,\n\u001b[32m   1027\u001b[39m     statement=operation,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1046\u001b[39m     resultRowLimit=row_limit,\n\u001b[32m   1047\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1048\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmake_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExecuteStatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m async_op:\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_execute_response_async(resp, cursor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/databricks/sql/backend/thrift_backend.py:512\u001b[39m, in \u001b[36mThriftDatabricksClient.make_request\u001b[39m\u001b[34m(self, method, request, retryable)\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, max_attempts + \u001b[32m1\u001b[39m):\n\u001b[32m    508\u001b[39m     \u001b[38;5;66;03m# We have a lock here because .cancel can be called from a separate thread.\u001b[39;00m\n\u001b[32m    509\u001b[39m     \u001b[38;5;66;03m# We do not want threads to be simultaneously sharing the Thrift Transport\u001b[39;00m\n\u001b[32m    510\u001b[39m     \u001b[38;5;66;03m# because we use its state to determine retries\u001b[39;00m\n\u001b[32m    511\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request_lock:\n\u001b[32m--> \u001b[39m\u001b[32m512\u001b[39m         response_or_error_info = \u001b[43mattempt_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    513\u001b[39m     elapsed = get_elapsed()\n\u001b[32m    515\u001b[39m     \u001b[38;5;66;03m# conditions: success, non-retry-able, no-attempts-left, no-time-left, delay+retry\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/databricks/sql/backend/thrift_backend.py:418\u001b[39m, in \u001b[36mThriftDatabricksClient.make_request.<locals>.attempt_request\u001b[39m\u001b[34m(attempt)\u001b[39m\n\u001b[32m    415\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.set_retry_command_type(this_command_type)\n\u001b[32m    416\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.startRetryTimer()\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m response = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# We need to call type(response) here because thrift doesn't implement __name__ attributes for thrift responses\u001b[39;00m\n\u001b[32m    421\u001b[39m logger.debug(\n\u001b[32m    422\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mReceived response: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m(<REDACTED>)\u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mtype\u001b[39m(response).\u001b[34m__name__\u001b[39m)\n\u001b[32m    423\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/databricks/sql/thrift_api/TCLIService/TCLIService.py:300\u001b[39m, in \u001b[36mClient.ExecuteStatement\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mExecuteStatement\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m    295\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[33;03m    Parameters:\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[33;03m     - req\u001b[39;00m\n\u001b[32m    298\u001b[39m \n\u001b[32m    299\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend_ExecuteStatement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recv_ExecuteStatement()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/databricks/sql/thrift_api/TCLIService/TCLIService.py:309\u001b[39m, in \u001b[36mClient.send_ExecuteStatement\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m    307\u001b[39m args.write(\u001b[38;5;28mself\u001b[39m._oprot)\n\u001b[32m    308\u001b[39m \u001b[38;5;28mself\u001b[39m._oprot.writeMessageEnd()\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_oprot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/databricks/sql/auth/thrift_http_client.py:193\u001b[39m, in \u001b[36mTHttpClient.flush\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    190\u001b[39m     headers.update(**custom_headers)\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# HTTP request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28mself\u001b[39m.__resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# Get reply to flush the request\u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;28mself\u001b[39m.code = \u001b[38;5;28mself\u001b[39m.__resp.status\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/urllib3/_request_methods.py:143\u001b[39m, in \u001b[36mRequestMethods.request\u001b[39m\u001b[34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request_encode_url(\n\u001b[32m    136\u001b[39m         method,\n\u001b[32m    137\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m         **urlopen_kw,\n\u001b[32m    141\u001b[39m     )\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43murlopen_kw\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/urllib3/_request_methods.py:278\u001b[39m, in \u001b[36mRequestMethods.request_encode_body\u001b[39m\u001b[34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[39m\n\u001b[32m    274\u001b[39m     extra_kw[\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m].setdefault(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m, content_type)\n\u001b[32m    276\u001b[39m extra_kw.update(urlopen_kw)\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/hassett-forecasting/venv/lib/python3.13/site-packages/urllib3/connection.py:571\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    568\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    570\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    574\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Cell 8: Query Hassett report table - FULL DATASET (no limit)\n",
    "# First, check how many rows exist in the source table\n",
    "count_query = \"SELECT COUNT(*) as row_count FROM decus_domesticops_prod.dbo.tmp_hassett_report\"\n",
    "count_result = pd.read_sql(count_query, conn)\n",
    "total_rows_in_db = count_result['row_count'][0]\n",
    "print(f\"Total rows in source table: {total_rows_in_db:,}\")\n",
    "\n",
    "# Now fetch all data\n",
    "query = \"SELECT * FROM decus_domesticops_prod.dbo.tmp_hassett_report\"\n",
    "print(f\"\\nFetching ALL rows from Databricks...\")\n",
    "df_hassett = pd.read_sql(query, conn)\n",
    "print(f\"âœ… Loaded {len(df_hassett):,} rows (COMPLETE dataset)\")\n",
    "print(f\"Columns ({len(df_hassett.columns)}): {list(df_hassett.columns)}\")\n",
    "\n",
    "if len(df_hassett) != total_rows_in_db:\n",
    "    print(f\"\\nâš ï¸  WARNING: Loaded {len(df_hassett):,} rows but source has {total_rows_in_db:,} rows!\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Confirmed: All {total_rows_in_db:,} rows loaded successfully\")\n",
    "\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df_hassett.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4jinbvupxrv",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/_0c_sls56fnf_plnrkksvd740000gn/T/ipykernel_25649/2265818463.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  count_result = pd.read_sql(count_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in source table: 360,296\n",
      "\n",
      "Fetching 10,000 sample rows from Databricks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/_0c_sls56fnf_plnrkksvd740000gn/T/ipykernel_25649/2265818463.py:12: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_hassett = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 10,000 rows (SAMPLE dataset)\n",
      "Columns (128): ['HASSETT', 'FACILITY', 'SHIPPER_NAME', 'SHIPPER_ADR_1', 'SHIPPER_ADR_2', 'SHIPPER_CITY', 'SHIPPER_STATE', 'SHIPPER_ZIP', 'SHIPPER_PHONE', 'SHIPPER_CONTACT', 'SHIPPER_REF_NO', 'SHIPPER', 'CONSIGNEE_NAME', 'CONSIGNEE_ADDRESS_1', 'CONSIGNEE_ADDRESS_2', 'CONSIGNEE_CITY', 'CONSIGNEE_STATE', 'CONSIGNEE_ZIP', 'CONSIGNEE_PHONE', 'CONSIGNEE_CONTACT', 'CONSIGNEE_REF_NO', 'CONSIGNEE', 'BILL_TO_NAME', 'BILL_TO_ADR_1', 'BILL_TO_ADR_2', 'BILL_TO_CITY', 'BILL_TO_STATE', 'BILL_TO_ZIP', 'BILL_TO_PHONE', 'BILL_TO_CONTACT', 'BILL_TO', 'DESCRIPTION_1', 'DESCRIPTION_2', 'DESCRIPTION_3', 'DESCRIPTION_4', 'SPECIAL_INSTRUCTIONS_1', 'SPECIAL_INSTRUCTIONS_2', 'SPECIAL_INSTRUCTIONS_3', 'RECEIVED_BY_POD', 'ORIGIN', 'DESTIN', 'CARRIER', 'FLIGHT', 'INVOICE', 'SERVICE_1', 'SERVICE_2', 'SERVICE_3', 'SERVICE_4', 'PIECES', 'WEIGHT', 'CUBIC_WEIGHT', 'COPY_COUNT', 'TOTAL_COST', 'AIR_COST', 'PICK_UP_COST', 'DELIVERY_COST', 'EXCESS_VALUE_COST', 'INSURANCE_COST', 'ADV_ORIGIN_COST', 'ADV_DESTIN_COST', 'OTHER_COST', 'FREIGHT_COD_COST', 'MECHANDISE_COD_COST', 'SURCHARGE_AIR_COST', 'SURCHARGE_CARTAGE_COST', 'SURCHARGE_SECURITY_COST', 'TOTAL2_COST', 'DATE_ISSUE', 'DATE_SHIP', 'INVOICE_DATE', 'DATE_RECEIVED', 'DEPARTURE', 'ARRIVAL', 'TIME_RECEIVED', 'owner', 'fileName', 'LoadDate', 'LoadDatetime', 'DW_INSERT_DATE', 'svc1', 'svc2', 'svc3', 'svc4', 'BillTo', 'ShipperName', 'ConsigneeName', 'ConsigneeCity', 'WeightBand', 'HAXServiceLevel', 'ProductType', 'ShipDay', 'ReceiveDay', 'WeekEnding', 'ODC', 'DDC', 'TransitDays', 'AdjTransitDays', 'InvoiceLagDays', 'NightFlag', 'WeekendFlag', 'CrossZoneFlag', 'HighValueFlag', 'Avg6WeekCost', 'StdDev6WeekCost', 'Avg6WeekWeight', 'StdDev6WeekWeight', 'Avg6WeekTransitDays', 'Pctl95InvoiceLag', 'Avg6WeekInvoiceLag', 'Avg6WeekPieces', 'Avg6WeekNightRate', 'Avg6WeekWeekendRate', 'TruckType', 'TruckFlow', 'ExpectedTransitDays', 'TransitVariance', 'OpsPortal_DN', 'OTM_Container', 'OTM_TU_Count', 'TransitException', 'NoPOD_Issue', 'NoPOD_Code', 'NoPOD_ID', 'CostAnomalyFlag', 'CostPctDiff', 'TagType', 'TagType_ID', 'ExpectedDeliveryDate']\n",
      "ðŸ“Š Sample represents 2.8% of total data\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HASSETT</th>\n",
       "      <th>FACILITY</th>\n",
       "      <th>SHIPPER_NAME</th>\n",
       "      <th>SHIPPER_ADR_1</th>\n",
       "      <th>SHIPPER_ADR_2</th>\n",
       "      <th>SHIPPER_CITY</th>\n",
       "      <th>SHIPPER_STATE</th>\n",
       "      <th>SHIPPER_ZIP</th>\n",
       "      <th>SHIPPER_PHONE</th>\n",
       "      <th>SHIPPER_CONTACT</th>\n",
       "      <th>SHIPPER_REF_NO</th>\n",
       "      <th>SHIPPER</th>\n",
       "      <th>CONSIGNEE_NAME</th>\n",
       "      <th>CONSIGNEE_ADDRESS_1</th>\n",
       "      <th>CONSIGNEE_ADDRESS_2</th>\n",
       "      <th>CONSIGNEE_CITY</th>\n",
       "      <th>CONSIGNEE_STATE</th>\n",
       "      <th>CONSIGNEE_ZIP</th>\n",
       "      <th>CONSIGNEE_PHONE</th>\n",
       "      <th>CONSIGNEE_CONTACT</th>\n",
       "      <th>CONSIGNEE_REF_NO</th>\n",
       "      <th>CONSIGNEE</th>\n",
       "      <th>BILL_TO_NAME</th>\n",
       "      <th>BILL_TO_ADR_1</th>\n",
       "      <th>BILL_TO_ADR_2</th>\n",
       "      <th>BILL_TO_CITY</th>\n",
       "      <th>BILL_TO_STATE</th>\n",
       "      <th>BILL_TO_ZIP</th>\n",
       "      <th>BILL_TO_PHONE</th>\n",
       "      <th>BILL_TO_CONTACT</th>\n",
       "      <th>BILL_TO</th>\n",
       "      <th>DESCRIPTION_1</th>\n",
       "      <th>DESCRIPTION_2</th>\n",
       "      <th>DESCRIPTION_3</th>\n",
       "      <th>DESCRIPTION_4</th>\n",
       "      <th>SPECIAL_INSTRUCTIONS_1</th>\n",
       "      <th>SPECIAL_INSTRUCTIONS_2</th>\n",
       "      <th>SPECIAL_INSTRUCTIONS_3</th>\n",
       "      <th>RECEIVED_BY_POD</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>DESTIN</th>\n",
       "      <th>CARRIER</th>\n",
       "      <th>FLIGHT</th>\n",
       "      <th>INVOICE</th>\n",
       "      <th>SERVICE_1</th>\n",
       "      <th>SERVICE_2</th>\n",
       "      <th>SERVICE_3</th>\n",
       "      <th>SERVICE_4</th>\n",
       "      <th>PIECES</th>\n",
       "      <th>WEIGHT</th>\n",
       "      <th>CUBIC_WEIGHT</th>\n",
       "      <th>COPY_COUNT</th>\n",
       "      <th>TOTAL_COST</th>\n",
       "      <th>AIR_COST</th>\n",
       "      <th>PICK_UP_COST</th>\n",
       "      <th>DELIVERY_COST</th>\n",
       "      <th>EXCESS_VALUE_COST</th>\n",
       "      <th>INSURANCE_COST</th>\n",
       "      <th>ADV_ORIGIN_COST</th>\n",
       "      <th>ADV_DESTIN_COST</th>\n",
       "      <th>OTHER_COST</th>\n",
       "      <th>FREIGHT_COD_COST</th>\n",
       "      <th>MECHANDISE_COD_COST</th>\n",
       "      <th>SURCHARGE_AIR_COST</th>\n",
       "      <th>SURCHARGE_CARTAGE_COST</th>\n",
       "      <th>SURCHARGE_SECURITY_COST</th>\n",
       "      <th>TOTAL2_COST</th>\n",
       "      <th>DATE_ISSUE</th>\n",
       "      <th>DATE_SHIP</th>\n",
       "      <th>INVOICE_DATE</th>\n",
       "      <th>DATE_RECEIVED</th>\n",
       "      <th>DEPARTURE</th>\n",
       "      <th>ARRIVAL</th>\n",
       "      <th>TIME_RECEIVED</th>\n",
       "      <th>owner</th>\n",
       "      <th>fileName</th>\n",
       "      <th>LoadDate</th>\n",
       "      <th>LoadDatetime</th>\n",
       "      <th>DW_INSERT_DATE</th>\n",
       "      <th>svc1</th>\n",
       "      <th>svc2</th>\n",
       "      <th>svc3</th>\n",
       "      <th>svc4</th>\n",
       "      <th>BillTo</th>\n",
       "      <th>ShipperName</th>\n",
       "      <th>ConsigneeName</th>\n",
       "      <th>ConsigneeCity</th>\n",
       "      <th>WeightBand</th>\n",
       "      <th>HAXServiceLevel</th>\n",
       "      <th>ProductType</th>\n",
       "      <th>ShipDay</th>\n",
       "      <th>ReceiveDay</th>\n",
       "      <th>WeekEnding</th>\n",
       "      <th>ODC</th>\n",
       "      <th>DDC</th>\n",
       "      <th>TransitDays</th>\n",
       "      <th>AdjTransitDays</th>\n",
       "      <th>InvoiceLagDays</th>\n",
       "      <th>NightFlag</th>\n",
       "      <th>WeekendFlag</th>\n",
       "      <th>CrossZoneFlag</th>\n",
       "      <th>HighValueFlag</th>\n",
       "      <th>Avg6WeekCost</th>\n",
       "      <th>StdDev6WeekCost</th>\n",
       "      <th>Avg6WeekWeight</th>\n",
       "      <th>StdDev6WeekWeight</th>\n",
       "      <th>Avg6WeekTransitDays</th>\n",
       "      <th>Pctl95InvoiceLag</th>\n",
       "      <th>Avg6WeekInvoiceLag</th>\n",
       "      <th>Avg6WeekPieces</th>\n",
       "      <th>Avg6WeekNightRate</th>\n",
       "      <th>Avg6WeekWeekendRate</th>\n",
       "      <th>TruckType</th>\n",
       "      <th>TruckFlow</th>\n",
       "      <th>ExpectedTransitDays</th>\n",
       "      <th>TransitVariance</th>\n",
       "      <th>OpsPortal_DN</th>\n",
       "      <th>OTM_Container</th>\n",
       "      <th>OTM_TU_Count</th>\n",
       "      <th>TransitException</th>\n",
       "      <th>NoPOD_Issue</th>\n",
       "      <th>NoPOD_Code</th>\n",
       "      <th>NoPOD_ID</th>\n",
       "      <th>CostAnomalyFlag</th>\n",
       "      <th>CostPctDiff</th>\n",
       "      <th>TagType</th>\n",
       "      <th>TagType_ID</th>\n",
       "      <th>ExpectedDeliveryDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52689565</td>\n",
       "      <td>5</td>\n",
       "      <td>DHL GLOBAL MAIL OF LOS ANGELES</td>\n",
       "      <td>3963 WORKMAN MILL ROAD</td>\n",
       "      <td>UNIT A</td>\n",
       "      <td>WHITTIER</td>\n",
       "      <td>CA</td>\n",
       "      <td>90601</td>\n",
       "      <td>562-760-4724</td>\n",
       "      <td>MARK STEVE VALDEZ</td>\n",
       "      <td></td>\n",
       "      <td>41430</td>\n",
       "      <td>DHL GLOBAL MAIL OF ATLANTA</td>\n",
       "      <td>1370 DISCOVERY INDUSTRIAL</td>\n",
       "      <td>COURT SE</td>\n",
       "      <td>MABLETON</td>\n",
       "      <td>GA</td>\n",
       "      <td>30126</td>\n",
       "      <td>901-647-8877</td>\n",
       "      <td>Lakiesha Long</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DHL GLOBAL MAIL OF ATLANTA</td>\n",
       "      <td>PO BOX 189103</td>\n",
       "      <td></td>\n",
       "      <td>PLANTATION</td>\n",
       "      <td>FL</td>\n",
       "      <td>33318</td>\n",
       "      <td>678/363-3390</td>\n",
       "      <td></td>\n",
       "      <td>41356.00</td>\n",
       "      <td></td>\n",
       "      <td>09/02/25 ISSUE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>LAX</td>\n",
       "      <td>ATL</td>\n",
       "      <td>006</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SDS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>frank.giles@dhl.com</td>\n",
       "      <td>Hassett_Raw_Data_2025352025-09-02T12:04:30.342...</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>2025-09-02 12:14:57.123</td>\n",
       "      <td>2025-12-12 18:25:18.828</td>\n",
       "      <td></td>\n",
       "      <td>SDS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>41356</td>\n",
       "      <td>DHL GLOBAL MAIL OF LOS ANGELES</td>\n",
       "      <td>DHL GLOBAL MAIL OF ATLANTA</td>\n",
       "      <td>MABLETON</td>\n",
       "      <td>0-10</td>\n",
       "      <td>SDS</td>\n",
       "      <td>EXP</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>LAX</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Delayed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTL</td>\n",
       "      <td>150.00</td>\n",
       "      <td>2025-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52675822</td>\n",
       "      <td>5</td>\n",
       "      <td>HASSETT EXPRESS LLC/COMAT</td>\n",
       "      <td>5214 W. 104TH STREET</td>\n",
       "      <td></td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CA</td>\n",
       "      <td>90045</td>\n",
       "      <td>310-645-4515</td>\n",
       "      <td>MEHDY NAITAKI</td>\n",
       "      <td></td>\n",
       "      <td>25111</td>\n",
       "      <td>DHL GLOBAL MAIL/SAN FRANCISCO</td>\n",
       "      <td>30041 AHERN AVE</td>\n",
       "      <td></td>\n",
       "      <td>UNION CITY</td>\n",
       "      <td>CA</td>\n",
       "      <td>94587</td>\n",
       "      <td>925-890-0212</td>\n",
       "      <td>Charles Vick</td>\n",
       "      <td></td>\n",
       "      <td>41359.00</td>\n",
       "      <td>HASSETT EXPRESS LLC/COMAT</td>\n",
       "      <td>5214 W. 104TH STREET</td>\n",
       "      <td></td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>CA</td>\n",
       "      <td>90045</td>\n",
       "      <td>310-645-4515</td>\n",
       "      <td>MEHDY NAITAKI</td>\n",
       "      <td>25111.00</td>\n",
       "      <td>15 PALLETS OF BOXES</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>WEEKLY DELIVERY WITH PRE-SCHEDULED</td>\n",
       "      <td>TRUCK</td>\n",
       "      <td></td>\n",
       "      <td>Manuel</td>\n",
       "      <td>SFO</td>\n",
       "      <td>SFO</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>52253204</td>\n",
       "      <td>GND</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>5250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14:00</td>\n",
       "      <td>frank.giles@dhl.com</td>\n",
       "      <td>Hassett_Raw_Data_2025392025-10-02T21:04:43.358...</td>\n",
       "      <td>2025-10-02</td>\n",
       "      <td>2025-10-02 21:09:58.782</td>\n",
       "      <td>2025-12-12 18:25:18.828</td>\n",
       "      <td>GND</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>25111</td>\n",
       "      <td>HASSETT EXPRESS LLC/COMAT</td>\n",
       "      <td>DHL GLOBAL MAIL/SAN FRANCISCO</td>\n",
       "      <td>UNION CITY</td>\n",
       "      <td>100+</td>\n",
       "      <td>GND</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>SFO</td>\n",
       "      <td>SFO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>376.34</td>\n",
       "      <td>423.09</td>\n",
       "      <td>4370.77</td>\n",
       "      <td>1365.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>None</td>\n",
       "      <td>DEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>On Time</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>-100.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52691223</td>\n",
       "      <td>5</td>\n",
       "      <td>DHL AVIATION CARGO-SFO</td>\n",
       "      <td>944 NORTH FIELD ROAD</td>\n",
       "      <td></td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>CA</td>\n",
       "      <td>94128</td>\n",
       "      <td>800-225-5345</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>41429</td>\n",
       "      <td>DHL eCOMMERCE</td>\n",
       "      <td>30041 AHERN AVE</td>\n",
       "      <td></td>\n",
       "      <td>UNION CITY</td>\n",
       "      <td>CA</td>\n",
       "      <td>94587</td>\n",
       "      <td>510-491-2183</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>DHL GLOBAL MAIL \"MAX\"</td>\n",
       "      <td>P.O BOX 189103</td>\n",
       "      <td></td>\n",
       "      <td>PLANTATION</td>\n",
       "      <td>FL</td>\n",
       "      <td>33318</td>\n",
       "      <td>678-363-3390</td>\n",
       "      <td>ACCOUNTS PAYABLE</td>\n",
       "      <td>41406.00</td>\n",
       "      <td>AVIATION</td>\n",
       "      <td>09/02/25 ISSUE</td>\n",
       "      <td>DHL AVIATION AWB# 99220183240;</td>\n",
       "      <td>99220183225</td>\n",
       "      <td>PICKUP FROM DHL AVIATION AT SFO AIRPORT</td>\n",
       "      <td>AND RUN DIRECTLY TO DHL eCOMMERCE IN</td>\n",
       "      <td>UNION CITY; CA.</td>\n",
       "      <td>MANUEL V</td>\n",
       "      <td>SFO</td>\n",
       "      <td>SFO</td>\n",
       "      <td>ACT2</td>\n",
       "      <td></td>\n",
       "      <td>52253220</td>\n",
       "      <td>BIL</td>\n",
       "      <td>GND</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>3962</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>815.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>755.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>815.40</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>14:00</td>\n",
       "      <td>frank.giles@dhl.com</td>\n",
       "      <td>Hassett_Raw_Data_2025392025-10-02T21:04:43.358...</td>\n",
       "      <td>2025-10-02</td>\n",
       "      <td>2025-10-02 21:09:58.782</td>\n",
       "      <td>2025-12-12 18:25:18.828</td>\n",
       "      <td>BIL</td>\n",
       "      <td>GND</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>41406</td>\n",
       "      <td>DHL AVIATION CARGO-SFO</td>\n",
       "      <td>DHL eCOMMERCE</td>\n",
       "      <td>UNION CITY</td>\n",
       "      <td>100+</td>\n",
       "      <td>GND</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>SFO</td>\n",
       "      <td>SFO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>376.34</td>\n",
       "      <td>423.09</td>\n",
       "      <td>4370.77</td>\n",
       "      <td>1365.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>ROLLERBED</td>\n",
       "      <td>P/U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>On Time</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>116.70</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52692034</td>\n",
       "      <td>3</td>\n",
       "      <td>DHL GLOBAL MAIL OF CHARLOTTE</td>\n",
       "      <td>8475 AUTOMATION DRIVE STE200</td>\n",
       "      <td></td>\n",
       "      <td>CONCORD</td>\n",
       "      <td>NC</td>\n",
       "      <td>28027</td>\n",
       "      <td>919-434-4943</td>\n",
       "      <td>TODD HAYES</td>\n",
       "      <td></td>\n",
       "      <td>41433</td>\n",
       "      <td>DHL GLOBAL MAIL OF CHARLOTTE</td>\n",
       "      <td>8475 AUTOMATION DRIVE</td>\n",
       "      <td>SUITE 200</td>\n",
       "      <td>CONCORD</td>\n",
       "      <td>NC</td>\n",
       "      <td>28027</td>\n",
       "      <td></td>\n",
       "      <td>JEFF OBRIEN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DHL GLOBAL MAIL OF ATLANTA</td>\n",
       "      <td>PO BOX 189103</td>\n",
       "      <td></td>\n",
       "      <td>PLANTATION</td>\n",
       "      <td>FL</td>\n",
       "      <td>33318</td>\n",
       "      <td>678/363-3390</td>\n",
       "      <td></td>\n",
       "      <td>41356.00</td>\n",
       "      <td>DHLGM</td>\n",
       "      <td>09/02/25 ISSUE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DELIVERY BILL</td>\n",
       "      <td></td>\n",
       "      <td>ST</td>\n",
       "      <td>BILLING ONLY</td>\n",
       "      <td>CLT</td>\n",
       "      <td>CLT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>52253219</td>\n",
       "      <td>BIL</td>\n",
       "      <td>GND</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>448.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>415.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>448.20</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-09-02</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>23:00</td>\n",
       "      <td>frank.giles@dhl.com</td>\n",
       "      <td>Hassett_Raw_Data_2025392025-10-02T21:04:43.358...</td>\n",
       "      <td>2025-10-02</td>\n",
       "      <td>2025-10-02 21:09:58.782</td>\n",
       "      <td>2025-12-12 18:25:18.828</td>\n",
       "      <td>BIL</td>\n",
       "      <td>GND</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>41356</td>\n",
       "      <td>DHL GLOBAL MAIL OF CHARLOTTE</td>\n",
       "      <td>DHL GLOBAL MAIL OF CHARLOTTE</td>\n",
       "      <td>CONCORD</td>\n",
       "      <td>0-10</td>\n",
       "      <td>GND</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>CLT</td>\n",
       "      <td>CLT</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>607.50</td>\n",
       "      <td>166.38</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>None</td>\n",
       "      <td>DEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>On Time</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>-26.20</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52688414</td>\n",
       "      <td>3</td>\n",
       "      <td>DHL GLOBAL MAIL OF CINCINNATI</td>\n",
       "      <td>2300 AIRPORT NORTH DRIVE</td>\n",
       "      <td></td>\n",
       "      <td>HEBRON</td>\n",
       "      <td>KY</td>\n",
       "      <td>41048</td>\n",
       "      <td>859-640-5166</td>\n",
       "      <td>GILBERT FLEEK</td>\n",
       "      <td></td>\n",
       "      <td>41360</td>\n",
       "      <td>DHL GLOBAL MAIL OF CINCINNATI</td>\n",
       "      <td>2300 AIRPORT NORTH DRIVE</td>\n",
       "      <td></td>\n",
       "      <td>HEBRON</td>\n",
       "      <td>KY</td>\n",
       "      <td>41048</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DHL GLOBAL MAIL OF ATLANTA</td>\n",
       "      <td>PO BOX 189103</td>\n",
       "      <td></td>\n",
       "      <td>PLANTATION</td>\n",
       "      <td>FL</td>\n",
       "      <td>33318</td>\n",
       "      <td>678/363-3390</td>\n",
       "      <td></td>\n",
       "      <td>41356.00</td>\n",
       "      <td></td>\n",
       "      <td>08/30/25 ISSUE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DELIVERY BILL ST</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>BILLING ONLY</td>\n",
       "      <td>CVG</td>\n",
       "      <td>CVG</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>52253201</td>\n",
       "      <td>BIL</td>\n",
       "      <td>GND</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>394.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>365.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>29.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>394.20</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-08-31</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>17:45</td>\n",
       "      <td>frank.giles@dhl.com</td>\n",
       "      <td>Hassett_Raw_Data_2025392025-09-30T21:03:46.298...</td>\n",
       "      <td>2025-09-30</td>\n",
       "      <td>2025-09-30 21:10:17.176</td>\n",
       "      <td>2025-12-12 18:25:18.828</td>\n",
       "      <td>BIL</td>\n",
       "      <td>GND</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>41356</td>\n",
       "      <td>DHL GLOBAL MAIL OF CINCINNATI</td>\n",
       "      <td>DHL GLOBAL MAIL OF CINCINNATI</td>\n",
       "      <td>HEBRON</td>\n",
       "      <td>0-10</td>\n",
       "      <td>GND</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2025-09-06</td>\n",
       "      <td>CVG</td>\n",
       "      <td>CVG</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>394.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>None</td>\n",
       "      <td>DEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>On Time</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HASSETT  FACILITY                    SHIPPER_NAME  \\\n",
       "0  52689565         5  DHL GLOBAL MAIL OF LOS ANGELES   \n",
       "1  52675822         5  HASSETT EXPRESS LLC/COMAT        \n",
       "2  52691223         5  DHL AVIATION CARGO-SFO           \n",
       "3  52692034         3  DHL GLOBAL MAIL OF CHARLOTTE     \n",
       "4  52688414         3  DHL GLOBAL MAIL OF CINCINNATI    \n",
       "\n",
       "                    SHIPPER_ADR_1                   SHIPPER_ADR_2  \\\n",
       "0  3963 WORKMAN MILL ROAD          UNIT A                           \n",
       "1  5214 W. 104TH STREET                                             \n",
       "2  944 NORTH FIELD ROAD                                             \n",
       "3  8475 AUTOMATION DRIVE STE200                                     \n",
       "4  2300 AIRPORT NORTH DRIVE                                         \n",
       "\n",
       "           SHIPPER_CITY SHIPPER_STATE SHIPPER_ZIP         SHIPPER_PHONE  \\\n",
       "0  WHITTIER                        CA       90601  562-760-4724           \n",
       "1  LOS ANGELES                     CA       90045  310-645-4515           \n",
       "2  SAN FRANCISCO                   CA       94128  800-225-5345           \n",
       "3  CONCORD                         NC       28027  919-434-4943           \n",
       "4  HEBRON                          KY       41048  859-640-5166           \n",
       "\n",
       "        SHIPPER_CONTACT     SHIPPER_REF_NO  SHIPPER  \\\n",
       "0  MARK STEVE VALDEZ                          41430   \n",
       "1  MEHDY NAITAKI                              25111   \n",
       "2                                             41429   \n",
       "3  TODD HAYES                                 41433   \n",
       "4  GILBERT FLEEK                              41360   \n",
       "\n",
       "                   CONSIGNEE_NAME             CONSIGNEE_ADDRESS_1  \\\n",
       "0  DHL GLOBAL MAIL OF ATLANTA      1370 DISCOVERY INDUSTRIAL        \n",
       "1  DHL GLOBAL MAIL/SAN FRANCISCO   30041 AHERN AVE                  \n",
       "2  DHL eCOMMERCE                   30041 AHERN AVE                  \n",
       "3  DHL GLOBAL MAIL OF CHARLOTTE    8475 AUTOMATION DRIVE            \n",
       "4  DHL GLOBAL MAIL OF CINCINNATI   2300 AIRPORT NORTH DRIVE         \n",
       "\n",
       "              CONSIGNEE_ADDRESS_2        CONSIGNEE_CITY CONSIGNEE_STATE  \\\n",
       "0  COURT SE                        MABLETON                          GA   \n",
       "1                                  UNION CITY                        CA   \n",
       "2                                  UNION CITY                        CA   \n",
       "3  SUITE 200                       CONCORD                           NC   \n",
       "4                                  HEBRON                            KY   \n",
       "\n",
       "  CONSIGNEE_ZIP       CONSIGNEE_PHONE     CONSIGNEE_CONTACT  \\\n",
       "0         30126  901-647-8877          Lakiesha Long          \n",
       "1         94587  925-890-0212          Charles Vick           \n",
       "2         94587  510-491-2183                                 \n",
       "3         28027                        JEFF OBRIEN            \n",
       "4         41048                                               \n",
       "\n",
       "    CONSIGNEE_REF_NO  CONSIGNEE                    BILL_TO_NAME  \\\n",
       "0  1                        NaN  DHL GLOBAL MAIL OF ATLANTA       \n",
       "1                      41359.00  HASSETT EXPRESS LLC/COMAT        \n",
       "2                           NaN  DHL GLOBAL MAIL \"MAX\"            \n",
       "3  1                        NaN  DHL GLOBAL MAIL OF ATLANTA       \n",
       "4  2                        NaN  DHL GLOBAL MAIL OF ATLANTA       \n",
       "\n",
       "                    BILL_TO_ADR_1                   BILL_TO_ADR_2  \\\n",
       "0  PO BOX 189103                                                    \n",
       "1  5214 W. 104TH STREET                                             \n",
       "2  P.O BOX 189103                                                   \n",
       "3  PO BOX 189103                                                    \n",
       "4  PO BOX 189103                                                    \n",
       "\n",
       "           BILL_TO_CITY BILL_TO_STATE BILL_TO_ZIP         BILL_TO_PHONE  \\\n",
       "0  PLANTATION                      FL       33318  678/363-3390           \n",
       "1  LOS ANGELES                     CA       90045  310-645-4515           \n",
       "2  PLANTATION                      FL       33318  678-363-3390           \n",
       "3  PLANTATION                      FL       33318  678/363-3390           \n",
       "4  PLANTATION                      FL       33318  678/363-3390           \n",
       "\n",
       "        BILL_TO_CONTACT  BILL_TO                   DESCRIPTION_1  \\\n",
       "0                       41356.00                                   \n",
       "1  MEHDY NAITAKI        25111.00  15 PALLETS OF BOXES              \n",
       "2  ACCOUNTS PAYABLE     41406.00  AVIATION                         \n",
       "3                       41356.00  DHLGM                            \n",
       "4                       41356.00                                   \n",
       "\n",
       "                      DESCRIPTION_2                     DESCRIPTION_3  \\\n",
       "0  09/02/25 ISSUE                                                       \n",
       "1                                                                       \n",
       "2  09/02/25 ISSUE                    DHL AVIATION AWB# 99220183240;     \n",
       "3  09/02/25 ISSUE                                                       \n",
       "4  08/30/25 ISSUE                                                       \n",
       "\n",
       "                      DESCRIPTION_4                   SPECIAL_INSTRUCTIONS_1  \\\n",
       "0                                                                              \n",
       "1                                    WEEKLY DELIVERY WITH PRE-SCHEDULED        \n",
       "2  99220183225                       PICKUP FROM DHL AVIATION AT SFO AIRPORT   \n",
       "3                                    DELIVERY BILL                             \n",
       "4                                    DELIVERY BILL ST                          \n",
       "\n",
       "                    SPECIAL_INSTRUCTIONS_2  \\\n",
       "0                                            \n",
       "1  TRUCK                                     \n",
       "2  AND RUN DIRECTLY TO DHL eCOMMERCE IN      \n",
       "3                                            \n",
       "4                                            \n",
       "\n",
       "                    SPECIAL_INSTRUCTIONS_3       RECEIVED_BY_POD ORIGIN  \\\n",
       "0                                                                   LAX   \n",
       "1                                           Manuel                  SFO   \n",
       "2  UNION CITY; CA.                          MANUEL V                SFO   \n",
       "3  ST                                       BILLING ONLY            CLT   \n",
       "4                                           BILLING ONLY            CVG   \n",
       "\n",
       "  DESTIN CARRIER FLIGHT   INVOICE SERVICE_1 SERVICE_2 SERVICE_3 SERVICE_4  \\\n",
       "0    ATL  006                                     SDS                       \n",
       "1    SFO                 52253204       GND                                 \n",
       "2    SFO  ACT2           52253220       BIL       GND                       \n",
       "3    CLT                 52253219       BIL       GND                       \n",
       "4    CVG                 52253201       BIL       GND                       \n",
       "\n",
       "   PIECES  WEIGHT  CUBIC_WEIGHT  COPY_COUNT  TOTAL_COST  AIR_COST  \\\n",
       "0       0       0             0           0        0.00      0.00   \n",
       "1      15    5250             0           0        0.00      0.00   \n",
       "2       2    3962             0           0      815.40      0.00   \n",
       "3       1       1             0           0      448.20      0.00   \n",
       "4       1       1             0           0      394.20      0.00   \n",
       "\n",
       "   PICK_UP_COST  DELIVERY_COST  EXCESS_VALUE_COST  INSURANCE_COST  \\\n",
       "0          0.00           0.00               0.00            0.00   \n",
       "1          1.00            NaN               0.00            0.00   \n",
       "2          0.00         755.00               0.00            0.00   \n",
       "3          0.00         415.00               0.00            0.00   \n",
       "4          0.00         365.00               0.00            0.00   \n",
       "\n",
       "   ADV_ORIGIN_COST  ADV_DESTIN_COST  OTHER_COST  FREIGHT_COD_COST  \\\n",
       "0             0.00             0.00        0.00              0.00   \n",
       "1             0.00             0.00        0.00              0.00   \n",
       "2             0.00             0.00        0.00              0.00   \n",
       "3             0.00             0.00        0.00              0.00   \n",
       "4             0.00             0.00        0.00              0.00   \n",
       "\n",
       "   MECHANDISE_COD_COST  SURCHARGE_AIR_COST  SURCHARGE_CARTAGE_COST  \\\n",
       "0                 0.00                0.00                    0.00   \n",
       "1                 0.00                0.00                    0.00   \n",
       "2                 0.00                0.00                   60.40   \n",
       "3                 0.00                0.00                   33.20   \n",
       "4                 0.00                0.00                   29.20   \n",
       "\n",
       "   SURCHARGE_SECURITY_COST  TOTAL2_COST  DATE_ISSUE   DATE_SHIP INVOICE_DATE  \\\n",
       "0                     0.00         0.00  2025-09-02  2025-09-02         None   \n",
       "1                     0.00         0.00        None  2025-09-02         None   \n",
       "2                     0.00       815.40  2025-09-02  2025-09-02         None   \n",
       "3                     0.00       448.20  2025-09-02  2025-09-02         None   \n",
       "4                     0.00       394.20  2025-08-31  2025-08-31         None   \n",
       "\n",
       "  DATE_RECEIVED DEPARTURE ARRIVAL TIME_RECEIVED                owner  \\\n",
       "0          None                            None  frank.giles@dhl.com   \n",
       "1    2025-09-02                           14:00  frank.giles@dhl.com   \n",
       "2    2025-09-02                           14:00  frank.giles@dhl.com   \n",
       "3    2025-09-02                           23:00  frank.giles@dhl.com   \n",
       "4    2025-08-31                           17:45  frank.giles@dhl.com   \n",
       "\n",
       "                                            fileName    LoadDate  \\\n",
       "0  Hassett_Raw_Data_2025352025-09-02T12:04:30.342...  2025-09-02   \n",
       "1  Hassett_Raw_Data_2025392025-10-02T21:04:43.358...  2025-10-02   \n",
       "2  Hassett_Raw_Data_2025392025-10-02T21:04:43.358...  2025-10-02   \n",
       "3  Hassett_Raw_Data_2025392025-10-02T21:04:43.358...  2025-10-02   \n",
       "4  Hassett_Raw_Data_2025392025-09-30T21:03:46.298...  2025-09-30   \n",
       "\n",
       "             LoadDatetime          DW_INSERT_DATE svc1 svc2 svc3 svc4 BillTo  \\\n",
       "0 2025-09-02 12:14:57.123 2025-12-12 18:25:18.828       SDS            41356   \n",
       "1 2025-10-02 21:09:58.782 2025-12-12 18:25:18.828  GND                 25111   \n",
       "2 2025-10-02 21:09:58.782 2025-12-12 18:25:18.828  BIL  GND            41406   \n",
       "3 2025-10-02 21:09:58.782 2025-12-12 18:25:18.828  BIL  GND            41356   \n",
       "4 2025-09-30 21:10:17.176 2025-12-12 18:25:18.828  BIL  GND            41356   \n",
       "\n",
       "                      ShipperName                  ConsigneeName  \\\n",
       "0  DHL GLOBAL MAIL OF LOS ANGELES     DHL GLOBAL MAIL OF ATLANTA   \n",
       "1       HASSETT EXPRESS LLC/COMAT  DHL GLOBAL MAIL/SAN FRANCISCO   \n",
       "2          DHL AVIATION CARGO-SFO                  DHL eCOMMERCE   \n",
       "3    DHL GLOBAL MAIL OF CHARLOTTE   DHL GLOBAL MAIL OF CHARLOTTE   \n",
       "4   DHL GLOBAL MAIL OF CINCINNATI  DHL GLOBAL MAIL OF CINCINNATI   \n",
       "\n",
       "  ConsigneeCity WeightBand HAXServiceLevel ProductType  ShipDay ReceiveDay  \\\n",
       "0      MABLETON       0-10             SDS         EXP  Tuesday       None   \n",
       "1    UNION CITY       100+             GND       LOCAL  Tuesday    Tuesday   \n",
       "2    UNION CITY       100+             GND       LOCAL  Tuesday    Tuesday   \n",
       "3       CONCORD       0-10             GND       LOCAL  Tuesday    Tuesday   \n",
       "4        HEBRON       0-10             GND       LOCAL   Sunday     Sunday   \n",
       "\n",
       "   WeekEnding  ODC  DDC  TransitDays  AdjTransitDays  InvoiceLagDays  \\\n",
       "0  2025-09-06  LAX  ATL          NaN             NaN               0   \n",
       "1  2025-09-06  SFO  SFO         0.00            0.00               0   \n",
       "2  2025-09-06  SFO  SFO         0.00            0.00               0   \n",
       "3  2025-09-06  CLT  CLT         0.00            0.00               0   \n",
       "4  2025-09-06  CVG  CVG         0.00           -1.00               0   \n",
       "\n",
       "   NightFlag  WeekendFlag  CrossZoneFlag  HighValueFlag  Avg6WeekCost  \\\n",
       "0          0            0              1              0           NaN   \n",
       "1          0            0              0              0        376.34   \n",
       "2          0            0              0              0        376.34   \n",
       "3          0            0              0              0        607.50   \n",
       "4          0            1              0              0        394.20   \n",
       "\n",
       "   StdDev6WeekCost  Avg6WeekWeight  StdDev6WeekWeight  Avg6WeekTransitDays  \\\n",
       "0              NaN             NaN                NaN                  NaN   \n",
       "1           423.09         4370.77            1365.82                 0.00   \n",
       "2           423.09         4370.77            1365.82                 0.00   \n",
       "3           166.38            1.00               0.00                 0.00   \n",
       "4             0.00            1.00               0.00                -1.00   \n",
       "\n",
       "   Pctl95InvoiceLag  Avg6WeekInvoiceLag  Avg6WeekPieces  Avg6WeekNightRate  \\\n",
       "0              0.00                0.00           49.50               0.00   \n",
       "1              0.00                0.00            3.27               0.00   \n",
       "2              0.00                0.00            3.27               0.00   \n",
       "3              0.00                0.00            1.00               0.00   \n",
       "4              0.00                0.00            1.00               0.00   \n",
       "\n",
       "   Avg6WeekWeekendRate  TruckType TruckFlow  ExpectedTransitDays  \\\n",
       "0                 0.00       None      None                 0.00   \n",
       "1                 0.10       None       DEL                  NaN   \n",
       "2                 0.10  ROLLERBED       P/U                  NaN   \n",
       "3                 0.17       None       DEL                  NaN   \n",
       "4                 0.19       None       DEL                  NaN   \n",
       "\n",
       "   TransitVariance OpsPortal_DN OTM_Container OTM_TU_Count TransitException  \\\n",
       "0              NaN         None          None         None          Delayed   \n",
       "1              NaN         None          None         None          On Time   \n",
       "2              NaN         None          None         None          On Time   \n",
       "3              NaN         None          None         None          On Time   \n",
       "4              NaN         None          None         None          On Time   \n",
       "\n",
       "  NoPOD_Issue NoPOD_Code  NoPOD_ID CostAnomalyFlag  CostPctDiff TagType  \\\n",
       "0        None       None       NaN            None          NaN     CTL   \n",
       "1        None       None       NaN          Normal      -100.00    None   \n",
       "2        None       None       NaN          Normal       116.70    None   \n",
       "3        None       None       NaN          Normal       -26.20    None   \n",
       "4        None       None       NaN          Normal         0.00    None   \n",
       "\n",
       "   TagType_ID ExpectedDeliveryDate  \n",
       "0      150.00           2025-09-02  \n",
       "1         NaN                 None  \n",
       "2         NaN                 None  \n",
       "3         NaN                 None  \n",
       "4         NaN                 None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query Hassett report table - Sample for testing\n",
    "# First, check how many rows exist in the source table\n",
    "count_query = \"SELECT COUNT(*) as row_count FROM decus_domesticops_prod.dbo.tmp_hassett_report\"\n",
    "count_result = pd.read_sql(count_query, conn)\n",
    "total_rows_in_db = count_result['row_count'][0]\n",
    "print(f\"Total rows in source table: {total_rows_in_db:,}\")\n",
    "\n",
    "# Fetch a sample for testing (10,000 rows)\n",
    "SAMPLE_SIZE = 10000\n",
    "query = f\"SELECT * FROM decus_domesticops_prod.dbo.tmp_hassett_report LIMIT {SAMPLE_SIZE}\"\n",
    "print(f\"\\nFetching {SAMPLE_SIZE:,} sample rows from Databricks...\")\n",
    "df_hassett = pd.read_sql(query, conn)\n",
    "print(f\"âœ… Loaded {len(df_hassett):,} rows (SAMPLE dataset)\")\n",
    "print(f\"Columns ({len(df_hassett.columns)}): {list(df_hassett.columns)}\")\n",
    "print(f\"ðŸ“Š Sample represents {len(df_hassett)/total_rows_in_db*100:.1f}% of total data\")\n",
    "\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df_hassett.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "qzsk8mklrr",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tier mapping loaded!\n",
      "\n",
      "ðŸ“Š ODC Tiers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODC</th>\n",
       "      <th>tier</th>\n",
       "      <th>total_2024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAX</td>\n",
       "      <td>Large</td>\n",
       "      <td>119209.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EWR</td>\n",
       "      <td>Large</td>\n",
       "      <td>94554.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IAD</td>\n",
       "      <td>Large</td>\n",
       "      <td>69074.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SLC</td>\n",
       "      <td>Large</td>\n",
       "      <td>63409.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>Medium</td>\n",
       "      <td>38689.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DFW</td>\n",
       "      <td>Medium</td>\n",
       "      <td>38280.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PHX</td>\n",
       "      <td>Medium</td>\n",
       "      <td>31310.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CVG</td>\n",
       "      <td>Medium</td>\n",
       "      <td>27612.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IAH</td>\n",
       "      <td>Medium</td>\n",
       "      <td>26011.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEA</td>\n",
       "      <td>Medium</td>\n",
       "      <td>23617.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ORD</td>\n",
       "      <td>Medium</td>\n",
       "      <td>20541.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MCI</td>\n",
       "      <td>Small</td>\n",
       "      <td>18713.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SFO</td>\n",
       "      <td>Small</td>\n",
       "      <td>18606.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CAK</td>\n",
       "      <td>Small</td>\n",
       "      <td>15444.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CLT</td>\n",
       "      <td>Small</td>\n",
       "      <td>15432.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MCO</td>\n",
       "      <td>Small</td>\n",
       "      <td>9628.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RDU</td>\n",
       "      <td>Small</td>\n",
       "      <td>9011.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DEN</td>\n",
       "      <td>Small</td>\n",
       "      <td>4536.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BOS</td>\n",
       "      <td>Small</td>\n",
       "      <td>2794.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DTW</td>\n",
       "      <td>Small</td>\n",
       "      <td>593.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ODC    tier  total_2024\n",
       "0   LAX   Large   119209.00\n",
       "1   EWR   Large    94554.00\n",
       "2   IAD   Large    69074.00\n",
       "3   SLC   Large    63409.00\n",
       "4   ATL  Medium    38689.00\n",
       "5   DFW  Medium    38280.00\n",
       "6   PHX  Medium    31310.00\n",
       "7   CVG  Medium    27612.00\n",
       "8   IAH  Medium    26011.00\n",
       "9   SEA  Medium    23617.00\n",
       "10  ORD  Medium    20541.00\n",
       "11  MCI   Small    18713.00\n",
       "12  SFO   Small    18606.00\n",
       "13  CAK   Small    15444.00\n",
       "14  CLT   Small    15432.00\n",
       "15  MCO   Small     9628.00\n",
       "16  RDU   Small     9011.00\n",
       "17  DEN   Small     4536.00\n",
       "18  BOS   Small     2794.00\n",
       "19  DTW   Small      593.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Tier Summary:\n",
      "        count  total_2024\n",
      "tier                     \n",
      "Large       4   346246.00\n",
      "Medium      7   206060.00\n",
      "Small       9    94757.00\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Check tier mapping\n",
    "tier_path = data_dir / 'odc_tier_mapping.csv'\n",
    "\n",
    "if tier_path.exists():\n",
    "    tiers = pd.read_csv(tier_path)\n",
    "    print(\"âœ… Tier mapping loaded!\\n\")\n",
    "    print(\"ðŸ“Š ODC Tiers:\")\n",
    "    display(tiers)\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ Tier Summary:\")\n",
    "    print(tiers.groupby('tier').agg({\n",
    "        'ODC': 'count',\n",
    "        'total_2024': 'sum'\n",
    "    }).rename(columns={'ODC': 'count'}))\n",
    "else:\n",
    "    print(f\"âš ï¸  Tier mapping not found at: {tier_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bs31gf1a7o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Sample Forecast Data (7900 rows):\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ODC</th>\n",
       "      <th>ProductType</th>\n",
       "      <th>PIECES</th>\n",
       "      <th>WEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LAX</td>\n",
       "      <td>MAX</td>\n",
       "      <td>10448</td>\n",
       "      <td>346872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SLC</td>\n",
       "      <td>MAX</td>\n",
       "      <td>6981</td>\n",
       "      <td>186087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EWR</td>\n",
       "      <td>EXP</td>\n",
       "      <td>6714</td>\n",
       "      <td>245953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SFO</td>\n",
       "      <td>EXP</td>\n",
       "      <td>6650</td>\n",
       "      <td>262334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IAD</td>\n",
       "      <td>MAX</td>\n",
       "      <td>5808</td>\n",
       "      <td>191553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SLC</td>\n",
       "      <td>EXP</td>\n",
       "      <td>5108</td>\n",
       "      <td>191279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DFW</td>\n",
       "      <td>MAX</td>\n",
       "      <td>4891</td>\n",
       "      <td>194981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EWR</td>\n",
       "      <td>MAX</td>\n",
       "      <td>4659</td>\n",
       "      <td>162615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CVG</td>\n",
       "      <td>MAX</td>\n",
       "      <td>4452</td>\n",
       "      <td>165914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PHX</td>\n",
       "      <td>EXP</td>\n",
       "      <td>4120</td>\n",
       "      <td>135512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ODC ProductType  PIECES  WEIGHT\n",
       "18  LAX         MAX   10448  346872\n",
       "32  SLC         MAX    6981  186087\n",
       "11  EWR         EXP    6714  245953\n",
       "29  SFO         EXP    6650  262334\n",
       "14  IAD         MAX    5808  191553\n",
       "31  SLC         EXP    5108  191279\n",
       "10  DFW         MAX    4891  194981\n",
       "12  EWR         MAX    4659  162615\n",
       "6   CVG         MAX    4452  165914\n",
       "25  PHX         EXP    4120  135512"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Forecasting test complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Quick forecasting test using the sample data we already loaded\n",
    "# Use the df_hassett DataFrame instead of querying again\n",
    "\n",
    "# Filter for MAX and EXP products from the sample\n",
    "sample_forecast = df_hassett[\n",
    "    (df_hassett['ProductType'].isin(['MAX', 'EXP'])) &\n",
    "    (df_hassett['DATE_SHIP'].notna())\n",
    "].copy()\n",
    "\n",
    "if len(sample_forecast) > 0:\n",
    "    print(f\"ðŸ“Š Sample Forecast Data ({len(sample_forecast)} rows):\\n\")\n",
    "    \n",
    "    # Group by ODC and ProductType\n",
    "    baseline = sample_forecast.groupby(['ODC', 'ProductType']).agg({\n",
    "        'PIECES': 'sum',\n",
    "        'WEIGHT': 'sum'\n",
    "    }).reset_index().sort_values('PIECES', ascending=False).head(10)\n",
    "    \n",
    "    display(baseline)\n",
    "    \n",
    "    print(\"\\nâœ… Forecasting test complete!\")\n",
    "else:\n",
    "    print(\"âš ï¸  No MAX/EXP products found in sample data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbzijsiydxo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENVIRONMENT SUMMARY\n",
      "============================================================\n",
      "\n",
      "âœ… Status Check:\n",
      "  âœ… Python packages\n",
      "  âœ… Project paths\n",
      "  âœ… Databricks connection\n",
      "  âœ… Hassett data loaded\n",
      "  âœ… Tier mapping\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ ALL CHECKS PASSED! You're ready to start forecasting!\n",
      "============================================================\n",
      "\n",
      "Next steps:\n",
      "  1. Explore the loaded Hassett data (df_hassett)\n",
      "  2. Review docs/META_ANALYSIS_100_EXPERIMENTS.md\n",
      "  3. Build forecasting models using the sample data\n",
      "\n",
      "Data Summary:\n",
      "  â€¢ Sample size: 10,000 rows\n",
      "  â€¢ Total in DB: 360,296 rows\n",
      "  â€¢ Columns: 128\n",
      "  â€¢ ODC tiers: 20 locations\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Environment Summary\n",
    "print(\"=\"*60)\n",
    "print(\"ENVIRONMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Update checks for Databricks setup\n",
    "checks = [\n",
    "    (\"Python packages\", True),\n",
    "    (\"Project paths\", True),\n",
    "    (\"Databricks connection\", conn is not None),\n",
    "    (\"Hassett data loaded\", 'df_hassett' in locals() and len(df_hassett) > 0),\n",
    "    (\"Tier mapping\", tier_path.exists()),\n",
    "]\n",
    "\n",
    "print(\"\\nâœ… Status Check:\")\n",
    "for check, status in checks:\n",
    "    symbol = \"âœ…\" if status else \"âŒ\"\n",
    "    print(f\"  {symbol} {check}\")\n",
    "\n",
    "all_good = all(status for _, status in checks)\n",
    "\n",
    "if all_good:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸŽ‰ ALL CHECKS PASSED! You're ready to start forecasting!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"  1. Explore the loaded Hassett data (df_hassett)\")\n",
    "    print(\"  2. Review docs/META_ANALYSIS_100_EXPERIMENTS.md\")\n",
    "    print(\"  3. Build forecasting models using the sample data\")\n",
    "    print(f\"\\nData Summary:\")\n",
    "    print(f\"  â€¢ Sample size: {len(df_hassett):,} rows\")\n",
    "    print(f\"  â€¢ Total in DB: 360,296 rows\")\n",
    "    print(f\"  â€¢ Columns: {len(df_hassett.columns)}\")\n",
    "    print(f\"  â€¢ ODC tiers: 20 locations\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"âš ï¸  SOME CHECKS FAILED\")\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
