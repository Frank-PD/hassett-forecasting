{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Forecast Demo\n",
    "\n",
    "**Purpose**: Generate a forecast using the winning methodology from 100+ experiments.\n",
    "\n",
    "**Approach**:\n",
    "- 2022 Week N baseline for MAX (93.46% accuracy)\n",
    "- 2024 Week N baseline for EXP (86.37% accuracy)\n",
    "- YoY trend adjustment\n",
    "- Fourier seasonal adjustment (1.27x for peak weeks)\n",
    "- Hybrid day-of-week distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Project paths\n",
    "project_root = Path.cwd().parent\n",
    "data_dir = project_root / 'data'\n",
    "db_path = data_dir / 'hassett.db'\n",
    "\n",
    "# Plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Load data\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    DATE_SHIP as date,\n",
    "    ODC,\n",
    "    DDC,\n",
    "    ProductType,\n",
    "    PIECES as pieces\n",
    "FROM hassett_report\n",
    "WHERE ProductType IN ('MAX', 'EXP')\n",
    "    AND DATE_SHIP IS NOT NULL\n",
    "    AND ODC IS NOT NULL\n",
    "    AND DDC IS NOT NULL\n",
    "ORDER BY DATE_SHIP\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, conn)\n",
    "conn.close()\n",
    "\n",
    "# Parse dates\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['week'] = df['date'].dt.isocalendar().week\n",
    "df['dayofweek'] = df['date'].dt.dayofweek\n",
    "df['dayofyear'] = df['date'].dt.dayofyear\n",
    "\n",
    "print(f\"üìä Loaded {len(df):,} records\")\n",
    "print(f\"üìÖ Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"\\nüì¶ Products: {', '.join(df['ProductType'].unique())}\")\n",
    "print(f\"üìç ODCs: {df['ODC'].nunique()}\")\n",
    "print(f\"üéØ DDCs: {df['DDC'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Forecast Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast target\n",
    "TARGET_WEEK = 51\n",
    "TARGET_YEAR = 2025\n",
    "\n",
    "# Seasonal adjustment (Fourier-based)\n",
    "# Week 50-52 are peak season (Christmas)\n",
    "SEASONAL_MULTIPLIERS = {\n",
    "    48: 1.20,  # Thanksgiving week\n",
    "    49: 1.25,  # Pre-peak\n",
    "    50: 1.27,  # Peak (2 weeks before Christmas)\n",
    "    51: 1.25,  # Peak (1 week before Christmas)\n",
    "    52: 1.15,  # Christmas week (lighter)\n",
    "}\n",
    "\n",
    "seasonal_multiplier = SEASONAL_MULTIPLIERS.get(TARGET_WEEK, 1.0)\n",
    "\n",
    "print(f\"üéØ Forecasting Target:\")\n",
    "print(f\"  Week: {TARGET_WEEK}\")\n",
    "print(f\"  Year: {TARGET_YEAR}\")\n",
    "print(f\"  Seasonal Multiplier: {seasonal_multiplier:.2f}x\")\n",
    "\n",
    "if TARGET_WEEK in SEASONAL_MULTIPLIERS:\n",
    "    print(f\"  ‚ö†Ô∏è  Peak season week detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Product-Specific Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline(df, target_week, product_type):\n",
    "    \"\"\"\n",
    "    Get baseline forecast using optimal historical period.\n",
    "    MAX: 2022 Week N (93.46% accuracy)\n",
    "    EXP: 2024 Week N (86.37% accuracy)\n",
    "    \"\"\"\n",
    "    baseline_year = 2022 if product_type == 'MAX' else 2024\n",
    "    \n",
    "    baseline = df[\n",
    "        (df['year'] == baseline_year) &\n",
    "        (df['week'] == target_week) &\n",
    "        (df['ProductType'] == product_type)\n",
    "    ].copy()\n",
    "    \n",
    "    # Aggregate by ODC, DDC, dayofweek\n",
    "    baseline_agg = baseline.groupby(['ODC', 'DDC', 'dayofweek'])['pieces'].mean().reset_index()\n",
    "    baseline_agg.columns = ['ODC', 'DDC', 'dayofweek', 'baseline']\n",
    "    baseline_agg['ProductType'] = product_type\n",
    "    baseline_agg['baseline_year'] = baseline_year\n",
    "    \n",
    "    return baseline_agg\n",
    "\n",
    "# Get baselines for both products\n",
    "baseline_max = get_baseline(df, TARGET_WEEK, 'MAX')\n",
    "baseline_exp = get_baseline(df, TARGET_WEEK, 'EXP')\n",
    "\n",
    "baseline_combined = pd.concat([baseline_max, baseline_exp], ignore_index=True)\n",
    "\n",
    "print(f\"üìä Baseline Statistics:\")\n",
    "print(f\"\\nMAX (2022 Week {TARGET_WEEK}):\")\n",
    "print(f\"  Routes: {len(baseline_max):,}\")\n",
    "print(f\"  Total: {baseline_max['baseline'].sum():,.0f} pieces\")\n",
    "\n",
    "print(f\"\\nEXP (2024 Week {TARGET_WEEK}):\")\n",
    "print(f\"  Routes: {len(baseline_exp):,}\")\n",
    "print(f\"  Total: {baseline_exp['baseline'].sum():,.0f} pieces\")\n",
    "\n",
    "print(f\"\\n‚úÖ Baseline calculated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: YoY Trend Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yoy_trend(df, target_week, product_type):\n",
    "    \"\"\"\n",
    "    Calculate Year-over-Year trend multiplier.\n",
    "    Compare recent 8 weeks to same 8 weeks last year.\n",
    "    \"\"\"\n",
    "    # Get recent 8 weeks from current year (before target week)\n",
    "    recent_weeks = range(target_week - 8, target_week)\n",
    "    \n",
    "    # Current year recent data\n",
    "    recent_data = df[\n",
    "        (df['year'] == TARGET_YEAR) &\n",
    "        (df['week'].isin(recent_weeks)) &\n",
    "        (df['ProductType'] == product_type)\n",
    "    ]\n",
    "    \n",
    "    # Last year same weeks\n",
    "    lastyear_data = df[\n",
    "        (df['year'] == TARGET_YEAR - 1) &\n",
    "        (df['week'].isin(recent_weeks)) &\n",
    "        (df['ProductType'] == product_type)\n",
    "    ]\n",
    "    \n",
    "    if len(recent_data) > 0 and len(lastyear_data) > 0:\n",
    "        recent_avg = recent_data['pieces'].mean()\n",
    "        lastyear_avg = lastyear_data['pieces'].mean()\n",
    "        trend = recent_avg / lastyear_avg if lastyear_avg > 0 else 1.0\n",
    "    else:\n",
    "        trend = 1.0\n",
    "    \n",
    "    return trend\n",
    "\n",
    "# Calculate trends\n",
    "trend_max = calculate_yoy_trend(df, TARGET_WEEK, 'MAX')\n",
    "trend_exp = calculate_yoy_trend(df, TARGET_WEEK, 'EXP')\n",
    "\n",
    "print(f\"üìà YoY Trend Multipliers:\")\n",
    "print(f\"  MAX: {trend_max:.3f}\")\n",
    "print(f\"  EXP: {trend_exp:.3f}\")\n",
    "\n",
    "if trend_max < 1.0:\n",
    "    print(f\"  ‚ö†Ô∏è  MAX trending down {(1-trend_max)*100:.1f}%\")\n",
    "elif trend_max > 1.0:\n",
    "    print(f\"  ‚úÖ MAX trending up {(trend_max-1)*100:.1f}%\")\n",
    "\n",
    "if trend_exp < 1.0:\n",
    "    print(f\"  ‚ö†Ô∏è  EXP trending down {(1-trend_exp)*100:.1f}%\")\n",
    "elif trend_exp > 1.0:\n",
    "    print(f\"  ‚úÖ EXP trending up {(trend_exp-1)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply trend and seasonal adjustments\n",
    "forecast = baseline_combined.copy()\n",
    "\n",
    "# Apply product-specific trends\n",
    "forecast['trend'] = forecast['ProductType'].map({'MAX': trend_max, 'EXP': trend_exp})\n",
    "\n",
    "# Calculate forecast\n",
    "forecast['forecast'] = (\n",
    "    forecast['baseline'] * \n",
    "    forecast['trend'] * \n",
    "    seasonal_multiplier\n",
    ")\n",
    "\n",
    "forecast['week'] = TARGET_WEEK\n",
    "forecast['year'] = TARGET_YEAR\n",
    "\n",
    "print(f\"‚úÖ Forecast Generated!\\n\")\n",
    "print(f\"üìä Forecast Summary (Week {TARGET_WEEK}, {TARGET_YEAR}):\")\n",
    "print(f\"\\nBy Product Type:\")\n",
    "summary = forecast.groupby('ProductType').agg({\n",
    "    'baseline': 'sum',\n",
    "    'forecast': 'sum'\n",
    "}).round(0)\n",
    "summary['change'] = ((summary['forecast'] - summary['baseline']) / summary['baseline'] * 100).round(1)\n",
    "print(summary)\n",
    "\n",
    "print(f\"\\nTotal Forecast: {forecast['forecast'].sum():,.0f} pieces\")\n",
    "print(f\"Total Baseline: {forecast['baseline'].sum():,.0f} pieces\")\n",
    "print(f\"Overall Change: {((forecast['forecast'].sum() - forecast['baseline'].sum()) / forecast['baseline'].sum() * 100):+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Aggregate by ODC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ODC-level forecast\n",
    "odc_forecast = forecast.groupby(['ODC', 'ProductType']).agg({\n",
    "    'baseline': 'sum',\n",
    "    'forecast': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Top 10 ODCs\n",
    "top_odcs = odc_forecast.groupby('ODC')['forecast'].sum().nlargest(10).index\n",
    "top_odc_data = odc_forecast[odc_forecast['ODC'].isin(top_odcs)].copy()\n",
    "\n",
    "print(f\"üìä Top 10 ODC Forecasts (Week {TARGET_WEEK}):\")\n",
    "print(\"\\nMAX:\")\n",
    "max_top = top_odc_data[top_odc_data['ProductType'] == 'MAX'].sort_values('forecast', ascending=False)\n",
    "print(max_top[['ODC', 'forecast']].to_string(index=False))\n",
    "\n",
    "print(\"\\nEXP:\")\n",
    "exp_top = top_odc_data[top_odc_data['ProductType'] == 'EXP'].sort_values('forecast', ascending=False)\n",
    "print(exp_top[['ODC', 'forecast']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Top ODCs by Product Type\n",
    "ax1 = axes[0, 0]\n",
    "top_pivot = top_odc_data.pivot(index='ODC', columns='ProductType', values='forecast').fillna(0)\n",
    "top_pivot.plot(kind='barh', ax=ax1, width=0.7)\n",
    "ax1.set_xlabel('Forecast (pieces)', fontweight='bold')\n",
    "ax1.set_title(f'Top 10 ODCs - Week {TARGET_WEEK} Forecast', fontweight='bold', fontsize=14)\n",
    "ax1.legend(title='Product')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 2. Product Type Split\n",
    "ax2 = axes[0, 1]\n",
    "product_totals = forecast.groupby('ProductType')['forecast'].sum()\n",
    "colors = ['#3498db', '#e74c3c']\n",
    "ax2.pie(product_totals, labels=product_totals.index, autopct='%1.1f%%', \n",
    "        colors=colors, startangle=90)\n",
    "ax2.set_title(f'Forecast Split by Product Type\\n(Week {TARGET_WEEK})', \n",
    "              fontweight='bold', fontsize=14)\n",
    "\n",
    "# 3. Day-of-Week Distribution\n",
    "ax3 = axes[1, 0]\n",
    "dow_forecast = forecast.groupby('dayofweek')['forecast'].sum()\n",
    "dow_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "dow_forecast.index = [dow_names[i] for i in dow_forecast.index]\n",
    "dow_forecast.plot(kind='bar', ax=ax3, color='steelblue', alpha=0.7)\n",
    "ax3.set_ylabel('Forecast (pieces)', fontweight='bold')\n",
    "ax3.set_xlabel('Day of Week', fontweight='bold')\n",
    "ax3.set_title('Day-of-Week Distribution', fontweight='bold', fontsize=14)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "plt.setp(ax3.xaxis.get_majorticklabels(), rotation=0)\n",
    "\n",
    "# 4. Baseline vs Forecast Comparison\n",
    "ax4 = axes[1, 1]\n",
    "comparison = forecast.groupby('ProductType').agg({\n",
    "    'baseline': 'sum',\n",
    "    'forecast': 'sum'\n",
    "}).reset_index()\n",
    "x = np.arange(len(comparison))\n",
    "width = 0.35\n",
    "ax4.bar(x - width/2, comparison['baseline'], width, label='Baseline', alpha=0.7)\n",
    "ax4.bar(x + width/2, comparison['forecast'], width, label='Forecast', alpha=0.7)\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(comparison['ProductType'])\n",
    "ax4.set_ylabel('Pieces', fontweight='bold')\n",
    "ax4.set_title('Baseline vs Forecast', fontweight='bold', fontsize=14)\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Visualizations generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save forecast to CSV\n",
    "output_path = project_root / 'data' / f'forecast_week_{TARGET_WEEK}_{TARGET_YEAR}.csv'\n",
    "forecast.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"üíæ Forecast saved to: {output_path}\")\n",
    "print(f\"\\nüìä Forecast contains {len(forecast):,} route-day combinations\")\n",
    "print(f\"üì¶ Total forecasted volume: {forecast['forecast'].sum():,.0f} pieces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(f\"FORECAST SUMMARY - Week {TARGET_WEEK}, {TARGET_YEAR}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Methodology:\")\n",
    "print(f\"  - MAX: 2022 Week {TARGET_WEEK} baseline (93.46% accuracy)\")\n",
    "print(f\"  - EXP: 2024 Week {TARGET_WEEK} baseline (86.37% accuracy)\")\n",
    "print(f\"  - YoY Trend: MAX={trend_max:.3f}, EXP={trend_exp:.3f}\")\n",
    "print(f\"  - Seasonal: {seasonal_multiplier:.2f}x multiplier\")\n",
    "\n",
    "print(f\"\\nüìà Results:\")\n",
    "print(f\"  - Total Forecast: {forecast['forecast'].sum():,.0f} pieces\")\n",
    "print(f\"  - MAX Forecast: {forecast[forecast['ProductType']=='MAX']['forecast'].sum():,.0f} pieces\")\n",
    "print(f\"  - EXP Forecast: {forecast[forecast['ProductType']=='EXP']['forecast'].sum():,.0f} pieces\")\n",
    "\n",
    "print(f\"\\nüìç Coverage:\")\n",
    "print(f\"  - ODCs: {forecast['ODC'].nunique()}\")\n",
    "print(f\"  - DDCs: {forecast['DDC'].nunique()}\")\n",
    "print(f\"  - Routes: {len(forecast[['ODC', 'DDC']].drop_duplicates())}\")\n",
    "\n",
    "print(f\"\\nüíæ Output:\")\n",
    "print(f\"  - File: {output_path.name}\")\n",
    "print(f\"  - Location: {output_path.parent}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ FORECAST COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
